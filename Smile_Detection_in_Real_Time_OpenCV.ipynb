{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smile Detection in Real-Time_OpenCV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRWcKB8WabB4Q5FVSPcA9O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandababugudipudi/Smile-Detection-in-Real-Time_OpenCV/blob/main/Smile_Detection_in_Real_Time_OpenCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIBd2YkcNqo"
      },
      "source": [
        "#**Smile Detection using OpenCV**\n",
        "\n",
        "Emotion detectors are used in many industries, one being the media industry where it is important for the companies to determine the public reactions. In this project, we are going to build a smile detector using OpenCV which takes in live feed from webcam. The smile/happiness detector that we are going to implement would be a raw one, there exist many better ways to implement it.\n",
        "\n",
        "Steps followed in this mini project are:\n",
        "1. Importing the necessary python libraries\n",
        "2. Including the desired HAAR-Cascades\n",
        "3. Writing a main function for detecting smile\n",
        "4. Executing the main function\n",
        "\n",
        "Let's start implementing the above steps one by one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtKytyin2qVi"
      },
      "source": [
        "###**1. Import the necessary libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DXqrFEk2uAA"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY8_SwGG5jDx"
      },
      "source": [
        "###**2. Including the desired HAAR-Cascades**\n",
        "\n",
        "Haar-cascades are classifiers that are used to detect features of face by superimposing predefined patterns over face segments and are used as XML files. In this model, we are going to use face and smile haar-cascades, which can be downloaded from [here](https://github.com/opencv/opencv/tree/master/data/haarcascades).\n",
        "\n",
        "1. Face Cascade [Link](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml)\n",
        "\n",
        "2. Smile Cascade [Link](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_smile.xml)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT-i_Mht65TE"
      },
      "source": [
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_eye.xml\")\n",
        "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_smile.xml\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8puNjV-B5mvs"
      },
      "source": [
        "###**3. Writing a main function for detecting smile**\n",
        "\n",
        "In this step, we will be building a main function which will perform the smile detection.\n",
        "1. The live feed coming from the webcam/video device is processed frame by frame. We process the gray scale image, as haar-cascades work better on them.\n",
        "2. To detect faces, we use `detectMultiScale` method. We can adjust the arguments according to our convenience to improve our detector.\n",
        "3. Then for each subsequent face detected we, need to check for smiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYOkIWyq8RH1"
      },
      "source": [
        "def detect(gray, frame):\n",
        "  detected_faces = face_cascade.detectMultiScale(\n",
        "      gray,\n",
        "      scaleFactor = 1.3,\n",
        "      minNeighbors = 5,\n",
        "      minSize = (30, 30)\n",
        "  )\n",
        "  for (x, y, width, height) in detected_faces:\n",
        "    cv2.rectangle(frame, (x, y), (x + width, y + height), (255, 0, 0), 2)\n",
        "    roi_gray = gray[y:y + height, x:x + width]\n",
        "    roi_color = frame[y:y + height, x:x + width]\n",
        "    detected_smiles = smile_cascade.detectMultiScale(\n",
        "        roi_gray,\n",
        "        scaleFactor = 1.8, \n",
        "        minNeighbors = 20\n",
        "    )\n",
        "    for (smile_x, smile_y, smile_width, smile_height) in detected_smiles:\n",
        "      cv2.rectangle(roi_gray, (smile_x, smile_y), (smile_x + smile_width, smile_y + smile_height), (0, 0, 255), 2)\n",
        "\n",
        "  return frame\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR5Lpqju5oHx"
      },
      "source": [
        "###**4. Executing the main function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "WpBlxVS6-p6g",
        "outputId": "4f6ca02d-6d15-4bd2-ccb3-121cf13e91a5"
      },
      "source": [
        "# Selecting the video capture device\n",
        "video_capture = cv2.VideoCapture(2)\n",
        "while True:\n",
        "  # Captures video_capture frame by frame\n",
        "  ret, frame = video_capture.read()\n",
        "  # Convert the captured image to GRAY\n",
        "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  # Calling the \"detect\" function\n",
        "  canvas = detect(gray, frame)\n",
        "  # Title of the video window\n",
        "  cv2.imshow('Real-Time Smile Detection using Webcam', canvas)\n",
        "  # The loop breaks once \"Q\" key is pressed\n",
        "  if cv2.waitKey(1) & 0xff == ord('q'):\n",
        "    break\n",
        "# Release the capture once all the processing is done.\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-88158ac49d43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_capture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# Convert the captured image to GRAY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;31m# Calling the \"detect\" function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mcanvas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    }
  ]
}